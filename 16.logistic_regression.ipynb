{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data_for_premium_paid.txt\"\n",
    "import csv\n",
    "from tools import *\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "def prccess_data(row):\n",
    "    return [float(row[0]), float(row[1]), float(row[2])]\n",
    "\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        data.append(prccess_data(row))\n",
    "        \n",
    "# Logistic function\n",
    "def logistic(x: float) -> float:\n",
    "    return 1.0 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "def logistic_prime(x: float) -> float:\n",
    "    y = logistic(x)\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def _negative_log_likelihood(x: Vector, y: float, beta: Vector) -> float:\n",
    "    if y == 1:\n",
    "        return -math.log(logistic(dot(x, beta)))\n",
    "    else:\n",
    "        return -math.log(1 - logistic(dot(x, beta)))\n",
    "\n",
    "\n",
    "def negative_log_likelihood(xs: List[Vector], ys: List[float], beta: Vector) -> float:\n",
    "    return sum(_negative_log_likelihood(x, y, beta) for x, y in zip(xs, ys))\n",
    "\n",
    "\n",
    "def _negative_log_partial_j(x: Vector, y: float, beta: Vector, j: int) -> float:\n",
    "    return -(y - logistic(dot(x, beta))) * x[j]\n",
    "\n",
    "\n",
    "def _negative_log_gradient(x: Vector, y: float, beta: Vector) -> Vector:\n",
    "    return [_negative_log_partial_j(x, y, beta, j) for j in range(len(beta))]\n",
    "\n",
    "\n",
    "def vector_sum(vectors: List[Vector]) -> Vector:\n",
    "    num_elements = len(vectors[0])\n",
    "    return [sum(vector[i] for vector in vectors) for i in range(num_elements)]\n",
    "\n",
    "\n",
    "def negative_log_gradient(xs: List[Vector], ys: List[float], beta: Vector) -> Vector:\n",
    "    return vector_sum([_negative_log_gradient(x, y, beta) for x, y in zip(xs, ys)])\n",
    "\n",
    "\n",
    "xs = [[1.0] + row[:2] for row in data]  # [1, experience, salary]\n",
    "ys = [row[2] for row in data]  # paid premium\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    learning_rate = 0.000001\n",
    "    rescaled_xs = rescale(xs)\n",
    "    \"\"\"\n",
    "    print(\"start:\")\n",
    "    beta = least_squares_fit(rescaled_xs, ys,learning_rate,num_steps=10000,batch_size=20)\n",
    "    print(\"beta:\", beta)\n",
    "    print(my_error_function(rescaled_xs, ys, beta))\n",
    "    predictions=[predict(x,beta) for x in rescaled_xs]\n",
    "    plt.scatter(predictions,ys)\n",
    "    plt.xlabel(\"predicted\")\n",
    "    plt.ylabel(\"actual\")\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 39.965 beta: [-2.0238042563970926, 4.680395586521536, -4.457913604878627]: 100%|██████████| 5000/5000 [00:08<00:00, 613.74it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta: [-2.0238042563970926, 4.680395586521536, -4.457913604878627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying the model\n",
    "random.seed(0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaled_xs, ys, 0.33)\n",
    "learning_rate = 0.01\n",
    "beta = [random.random() for _ in range(3)]\n",
    "with tqdm.trange(5000)as t:\n",
    "    for epoch in t:\n",
    "        gradient = negative_log_gradient(x_train, y_train, beta)\n",
    "        beta = gradient_step(beta, gradient, -learning_rate)\n",
    "        loss = negative_log_likelihood(x_train, y_train, beta)\n",
    "        t.set_description(f\"loss: {loss:.3f} beta: {beta}\")\n",
    "print(\"beta:\", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.925163958380162, 1.648026614972372, -0.00028764325691767867]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means, stdevs=scale(xs)\n",
    "beta_unscaled=[beta[0]\n",
    "               -beta[1]*means[1]/stdevs[1]\n",
    "               -beta[2]*means[2]/stdevs[2],\n",
    "               beta[1]/stdevs[1],\n",
    "               beta[2]/stdevs[2]]\n",
    "beta_unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives=false_positives=true_negatives=false_negatives=0\n",
    "false_negatives = 0\n",
    "\n",
    "for x_i, y_i in zip(x_test, y_test):\n",
    "    prediction = logistic(dot(beta, x_i))\n",
    "    if y_i == 1 and prediction >= 0.5:\n",
    "        true_positives += 1\n",
    "    elif y_i == 1 and prediction < 0.5:\n",
    "        false_negatives += 1\n",
    "    elif y_i == 0 and prediction < 0.5:\n",
    "        true_negatives += 1\n",
    "    elif y_i == 0 and prediction >= 0.5:\n",
    "        false_positives += 1\n",
    "precision=get_precision(true_positives,false_positives,false_negatives,true_negatives)\n",
    "recall=get_recall(true_positives,false_positives,false_negatives,true_negatives)\n",
    "precision,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06985848081186027,\n",
       " 0.06566095152214751,\n",
       " 0.24987785176913332,\n",
       " 0.983290312308836,\n",
       " 0.6063679439951916,\n",
       " 0.013555757883615578,\n",
       " 0.29253149125130146,\n",
       " 0.005267463969470931,\n",
       " 0.03270207298512329,\n",
       " 0.7537639359449452,\n",
       " 0.833727219413262,\n",
       " 0.775827921480921,\n",
       " 0.007085804799438884,\n",
       " 0.0006203872830060474,\n",
       " 0.04338138356178208,\n",
       " 0.001389066184521954,\n",
       " 0.02568701850813825,\n",
       " 0.0005614863913632178,\n",
       " 0.1138849866006537,\n",
       " 0.023555902894181635,\n",
       " 0.1511941614449637,\n",
       " 0.08933422458913565,\n",
       " 0.09333701374386985,\n",
       " 0.0001556717533126062,\n",
       " 0.07305863097720988,\n",
       " 0.010740802463219689,\n",
       " 0.45588141187831094,\n",
       " 0.030834999261163197,\n",
       " 0.07127627752870472,\n",
       " 0.12408376724252357,\n",
       " 0.5979428044976739,\n",
       " 0.7658919378730709,\n",
       " 1.8993848585776147e-05,\n",
       " 0.13843339682657926,\n",
       " 0.5583140497654323,\n",
       " 0.15689875708974138,\n",
       " 0.9642550019683719,\n",
       " 0.12330856830690173,\n",
       " 0.002501907550473461,\n",
       " 0.11776218956481337,\n",
       " 0.003919590296365597,\n",
       " 0.8313576208368463,\n",
       " 0.0028311618077155425,\n",
       " 0.009537495238909477,\n",
       " 0.20846089476170027,\n",
       " 0.00907930894562475,\n",
       " 0.9822872252334235,\n",
       " 0.8842512242766899,\n",
       " 0.16338575434985925,\n",
       " 0.011825951463673445,\n",
       " 0.9810669125208639,\n",
       " 0.04597211107315427,\n",
       " 0.8443852571266448,\n",
       " 0.0067445969744420065,\n",
       " 0.0002613519293571126,\n",
       " 0.5348464898529047,\n",
       " 0.3307037691834195,\n",
       " 0.032741180993731966,\n",
       " 0.28182033562178843,\n",
       " 0.9640076854572681,\n",
       " 0.03383305176812443,\n",
       " 0.4426690949692962,\n",
       " 0.10666400301842875,\n",
       " 0.002638784384219263,\n",
       " 0.013784929683986317,\n",
       " 0.01435478833964495]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=[logistic(dot(beta, x_i)) for x_i in x_test]\n",
    "plt.scatter(predictions,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
